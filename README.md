# ğŸ–ï¸ Sign_Language_Detection
This project detects and recognizes sign language gestures in real-time using Computer Vision and a pre-trained Machine Learning model. The goal is to help bridge communication between sign language users and non-users.

## ğŸ“Œ Features

âœ… Live webcam streaming for gesture detection

âœ… Hand detection using cvzone.HandTrackingModule

âœ… Gesture classification with a custom-trained Keras model (keras_model.h5)

âœ… Gesture list panel with images for reference

âœ… Interactive Streamlit web app with user-friendly UI

## ğŸš€ Tech Stack

*ï¸âƒ£ Python

*ï¸âƒ£ Streamlit â€“ for web interface

*ï¸âƒ£ OpenCV (cv2) â€“ for video processing

*ï¸âƒ£ cvzone â€“ for hand tracking

*ï¸âƒ£ TensorFlow/Keras â€“ for model training and inference

*ï¸âƒ£ NumPy â€“ for array operations

## ğŸ“‚Project Structure

Sign-Language-Detection/

â”‚

â”œâ”€â”€ app.py                  # Main Streamlit application

â”œâ”€â”€ requirements.txt        # Dependencies

â”œâ”€â”€ README.md               # Project documentation

â”‚

â”œâ”€â”€ Model/                  # Pre-trained model and labels

â”‚   â”œâ”€â”€ keras_model.h5

â”‚   â””â”€â”€ labels.txt

â”‚

â”œâ”€â”€ images/                 # Gesture reference images

â”‚   â”œâ”€â”€ hello.jpg

â”‚   â”œâ”€â”€ yes.jpg

â”‚   â”œâ”€â”€ no.jpg

â”‚   â”œâ”€â”€ help.jpg

â”‚   â””â”€â”€ ...

â””â”€â”€ 

## âš™ï¸ Installation

#### 1)Clone this repository:

```bash
git clone https://github.com/CHENNAMSETTYGURUTEJA/Sign_Language.git
cd Sign_Language
```

#### 2)Create and activate a virtual environment:

```bash
python -m venv env
```

####  Activate it on Windows

```bash
env\Scripts\activate
```

#### Activate it on Mac/Linux
```bash
source env/bin/activate
```

#### 3)Install dependencies:

```bash
pip install -r requirements.txt
```

#### 4)Run the Streamlit app:

```bash
streamlit run app.py
```

## ğŸ¯ Usage

1ï¸âƒ£ Launch the app.

2ï¸âƒ£ The gesture list panel on the left shows available gestures with sample images.

3ï¸âƒ£ Allow webcam access.

4ï¸âƒ£ Perform any gesture in front of the camera.

5ï¸âƒ£ The app will display the prediction in real-time.

## ğŸ–¼ï¸ Example Output

![IMG_20250908_204944](https://github.com/user-attachments/assets/6217c65f-8509-4a4b-9881-085496a1edef)
![IMG_20250908_204923](https://github.com/user-attachments/assets/3fd9d04d-e9fa-448c-b74f-a0275c5fe795)


